import streamlit as st
import google.generativeai as genai
import PyPDF2
import io

def extract_text_from_pdf(pdf_file):
    pdf_reader = PyPDF2.PdfReader(pdf_file)
    text = ""
    for page in pdf_reader.pages:
        text += page.extract_text()
    return text

def main():
    st.set_page_config(page_title="ì‚¬ë‚´ í•™ìŠµ ì œë„ ì•ˆë‚´ ì±—ë´‡")
    
    st.title("ğŸ“ ì‚¬ë‚´ í•™ìŠµ ì œë„ ì•ˆë‚´ ì±—ë´‡")
    st.markdown("---")
    
    # ì‚¬ì´ë“œë°”ì— API í‚¤ ì…ë ¥
    with st.sidebar:
        st.header("ì„¤ì •")
        api_key = st.text_input("Google API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", type="password")
        st.markdown("---")
        uploaded_file = st.file_uploader("ì‚¬ë‚´ í•™ìŠµ ì œë„ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['pdf'])
    
    if api_key:
        genai.configure(api_key=api_key)
        
        if uploaded_file is not None:
            # PDF ë‚´ìš©ì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
            if 'pdf_content' not in st.session_state:
                st.session_state.pdf_content = extract_text_from_pdf(uploaded_file)
                st.success("PDF íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            # ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”
            if 'chat_history' not in st.session_state:
                st.session_state.chat_history = []
            
            # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
            st.markdown("### ğŸ’¬ ì‚¬ë‚´ í•™ìŠµ ì œë„ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”!")
            
            # ì´ì „ ëŒ€í™” ë‚´ìš© í‘œì‹œ
            for chat in st.session_state.chat_history:
                if chat['role'] == 'user':
                    st.write(f"ğŸ™‹â€â™‚ï¸ **ì§ˆë¬¸**: {chat['content']}")
                else:
                    st.write(f"ğŸ¤– **ë‹µë³€**: {chat['content']}")
            
            # ì‚¬ìš©ì ì…ë ¥
            user_question = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", key="user_input")
            
            if user_question:
                try:
                    # Gemini ëª¨ë¸ ì„¤ì •
                    model = genai.GenerativeModel('gemini-pro')
                    
                    # í”„ë¡¬í”„íŠ¸ ì‘ì„±
                    prompt = f"""
                    ë‹¹ì‹ ì€ ì‚¬ë‚´ í•™ìŠµ ì œë„ ì•ˆë‚´ ì±—ë´‡ì…ë‹ˆë‹¤. 
                    ë‹¤ìŒ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
                    
                    ë¬¸ì„œ ë‚´ìš©:
                    {st.session_state.pdf_content}
                    
                    ì§ˆë¬¸: {user_question}
                    """
                    
                    # ì‘ë‹µ ìƒì„±
                    response = model.generate_content(prompt)
                    
                    # ì±„íŒ… ê¸°ë¡ ì €ì¥
                    st.session_state.chat_history.append({"role": "user", "content": user_question})
                    st.session_state.chat_history.append({"role": "assistant", "content": response.text})
                    
                    # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
                    st.rerun()
                    
                except Exception as e:
                    st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        
        else:
            st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    else:
        st.warning("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main()